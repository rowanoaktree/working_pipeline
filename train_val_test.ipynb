{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on work laptop\n",
    "usfws = pd.read_csv(\"C:\\Users\\rowanconverse\\OneDrive - University of New Mexico\\CV4Ecology\\Prototyping\\Data\\Labels\\train_val_test\\20230307_expertconsensuslabels.csv\")\n",
    "dgc = pd.read_csv(\"C:\\Users\\rowanconverse\\OneDrive - University of New Mexico\\CV4Ecology\\Prototyping\\Data\\Labels\\train_val_test\\20230307_zooniverseconsensuslabels.csv\")\n",
    "seagull = pd.read_csv(\"C:\\Users\\rowanconverse\\OneDrive - University of New Mexico\\CV4Ecology\\Prototyping\\Data\\Labels\\train_val_test\\20230307_zooniverseconsensuslabels_seagull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on home laptop\n",
    "usfws = pd.read_csv(\"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/train_val_test/20230307_expertconsensuslabels.csv\")\n",
    "dgc = pd.read_csv(\"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/train_val_test/20230307_zooniverseconsensuslabels.csv\")\n",
    "seagull = pd.read_csv(\"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/train_val_test/20230307_zooniverseconsensuslabels_seagull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all Zooniverse annotations, remove \"Other\" annotations, re-code category IDs, clean columns; add temporary \"basefile\" column\n",
    "zoo = pd.concat([dgc,seagull])\n",
    "zoo = zoo.reset_index(drop=True)\n",
    "zoo = zoo.drop('Unnamed: 0', axis=1)\n",
    "zoo = zoo[zoo[\"category\"] != 'Other Bird']\n",
    "categories = {\"Crane\": 1, 'Goose': 2, 'Duck': 3, 'Seagull': 4}\n",
    "zoo['category_id'] = zoo['category'].map(categories)\n",
    "zoo[\"basefile\"] = [x[:-10] for x in zoo['filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all \"Other\" IDs; re-code category IDs to match Zooniverse; clean columns\n",
    "usfws = usfws.drop('Unnamed: 0', axis=1)\n",
    "usfws = usfws[usfws[\"category\"] != 'Other']\n",
    "mapping = {'Canadian Goose': 'Goose',\n",
    "           'Sandhill Crane': 'Crane',\n",
    "           'Mallard': 'Duck',\n",
    "           'Northern Pintail': 'Duck',\n",
    "           'American Wigeon': 'Duck',\n",
    "           'Ringneck': 'Duck',\n",
    "           \"Ruddy\": 'Duck',\n",
    "           \"Readhead\": \"Duck\",\n",
    "           \"Snow Goose\": \"Goose\",\n",
    "           'Other': 'Other',\n",
    "           'Teal': 'Duck',\n",
    "           'Gadwall': 'Duck',\n",
    "           'Northern Shoveler': 'Duck'}\n",
    "default = 'Duck'\n",
    "usfws[\"superclass\"] = usfws[\"category\"].map(mapping).fillna(default)\n",
    "usfws[\"category_id\"] = usfws[\"superclass\"].map(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6265938811260032\n",
      "0.1009831479746337\n",
      "0.1749908339104575\n",
      "0.09743213698890564\n"
     ]
    }
   ],
   "source": [
    "duck = len(zoo.loc[zoo[\"category_id\"] == 3]) / len(zoo)\n",
    "goose = len(zoo.loc[zoo[\"category_id\"] == 2]) / len(zoo)\n",
    "crane = len(zoo.loc[zoo[\"category_id\"] == 1]) / len(zoo)\n",
    "sea = len(zoo.loc[zoo[\"category_id\"] == 4]) / len(zoo)\n",
    "print(duck)\n",
    "print(goose)\n",
    "print(crane)\n",
    "print(sea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167028199566161\n",
      "0.06073752711496746\n",
      "0.022559652928416486\n"
     ]
    }
   ],
   "source": [
    "duck = len(usfws.loc[usfws[\"category_id\"] == 3]) / len(usfws)\n",
    "goose = len(usfws.loc[usfws[\"category_id\"] == 2]) / len(usfws)\n",
    "crane = len(usfws.loc[usfws[\"category_id\"] == 1]) / len(usfws)\n",
    "print(duck)\n",
    "print(goose)\n",
    "print(crane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                 superclass\n",
       "BDA_12C_20181127_1.JPG   Goose          46\n",
       "                         Duck           30\n",
       "                         Crane           9\n",
       "BDA_12C_20181127_2.JPG   Duck          404\n",
       "                         Goose          19\n",
       "                         Crane           7\n",
       "BDA_12C_20181127_3.JPG   Duck          761\n",
       "                         Goose          24\n",
       "BDA_18A4_20181106_1.JPG  Duck          163\n",
       "BDA_18A4_20181106_2.JPG  Duck          353\n",
       "                         Crane           2\n",
       "BDA_18A4_20181106_3.JPG  Duck           62\n",
       "BDA_18A4_20181106_4.JPG  Duck          113\n",
       "BDA_18A4_20181107_1.JPG  Duck           66\n",
       "                         Crane          11\n",
       "BDA_18A4_20181107_2.JPG  Goose          15\n",
       "                         Duck           10\n",
       "                         Crane           1\n",
       "BDA_18A4_20181107_3.JPG  Duck           89\n",
       "BDA_18A4_20181107_4.JPG  Duck           62\n",
       "                         Crane          22\n",
       "mxw_L13_20181215_1.JPG   Goose          36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = usfws.groupby([\"filename\"]).value_counts([\"superclass\"])\n",
    "group\n",
    "#for key, item in group:\n",
    "#    print(group.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "3\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "ptrain = [\"BDA_12C_20181127_3.JPG\", \"BDA_18A4_20181106_2.JPG\",\"BDA_18A4_20181107_1.JPG\",\"BDA_18A4_20181107_2.JPG\", \"BDA_18A4_20181107_3.JPG\", \"BDA_18A4_20181107_4.JPG\"]\n",
    "pval = [\"BDA_12C_20181127_2.JPG\",\"BDA_18A4_20181106_1.JPG\",\"BDA_18A4_20181106_4.JPG\"]\n",
    "ptest = [\"BDA_12C_20181127_1.JPG\",\"BDA_18A4_20181106_3.JPG\",\"mxw_L13_20181215_1.JPG\"]\n",
    "\n",
    "print(len(ptrain))\n",
    "print(len(pval))\n",
    "print(len(ptest))\n",
    "print(bool(set(ptrain) & set(pval)))\n",
    "print(bool(set(pval) & set(ptest)))\n",
    "print(bool(set(ptest) & set(ptrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train group class counts:\n",
      "Duck     1341\n",
      "Goose      39\n",
      "Crane      36\n",
      "Name: superclass, dtype: int64\n",
      "\n",
      "Validation group class counts:\n",
      "Duck     680\n",
      "Goose     19\n",
      "Crane      7\n",
      "Name: superclass, dtype: int64\n",
      "\n",
      "Test group class counts:\n",
      "Duck     92\n",
      "Goose    82\n",
      "Crane     9\n",
      "Name: superclass, dtype: int64\n",
      "\n",
      " total labels: \n",
      "Duck     2113\n",
      "Goose     140\n",
      "Crane      52\n",
      "Name: superclass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the column name for the class labels\n",
    "class_column = 'superclass'\n",
    "\n",
    "# Split the dataframe into separate groups\n",
    "train_df = usfws[usfws['filename'].isin(ptrain)]\n",
    "val_df = usfws[usfws['filename'].isin(pval)]\n",
    "test_df = usfws[usfws['filename'].isin(ptest)]\n",
    "\n",
    "# Save the splits to separate CSV files\n",
    "save = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/train_val_test/usfws_splits/\" \n",
    "train_df.to_csv(save+'train.csv', index=False)\n",
    "val_df.to_csv(save+'val.csv', index=False)\n",
    "test_df.to_csv(save+'test.csv', index=False)\n",
    "\n",
    "# Calculate the count of labels for each class in each group\n",
    "train_counts = usfws[usfws['filename'].isin(ptrain)][class_column].value_counts()\n",
    "val_counts = usfws[usfws['filename'].isin(pval)][class_column].value_counts()\n",
    "test_counts = usfws[usfws['filename'].isin(ptest)][class_column].value_counts()\n",
    "\n",
    "# Print the count of labels for each class in each group\n",
    "print('Train group class counts:')\n",
    "print(train_counts)\n",
    "\n",
    "print('\\nValidation group class counts:')\n",
    "print(val_counts)\n",
    "\n",
    "print('\\nTest group class counts:')\n",
    "print(test_counts)\n",
    "print(\"\\n total labels: \")\n",
    "print(test_counts+train_counts+val_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duck     2113\n",
       "Goose     140\n",
       "Crane      52\n",
       "Name: superclass, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usfws[\"superclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "Goose    1.0\n",
      "Name: superclass, dtype: float64\n",
      "\n",
      "Validation set class distribution:\n",
      "Duck     0.931247\n",
      "Goose    0.045835\n",
      "Crane    0.022918\n",
      "Name: superclass, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "Series([], Name: superclass, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#SPLIT EXPERT: This was not effective for such a small number of images, so I did the manual split above. But preserving this as a record.\n",
    "\n",
    "# Define the desired class distribution in the train, validation, and test sets\n",
    "class_distribution = {'Crane': 0.02, 'Goose': 0.06, 'Duck': 0.92}\n",
    "\n",
    "# Calculate the total number of images in the dataset\n",
    "total_images = usfws['filename'].nunique()\n",
    "\n",
    "# Calculate the desired number of images for each class in the train, validation, and test sets\n",
    "desired_class_counts = {cls: int(count * total_images) for cls, count in class_distribution.items()}\n",
    "\n",
    "# Create a dictionary to store the assigned images for each set and class\n",
    "assigned_images = defaultdict(dict)\n",
    "\n",
    "# Shuffle the unique images\n",
    "unique_images = usfws['filename'].unique()\n",
    "np.random.shuffle(unique_images)\n",
    "\n",
    "# Assign images to sets while maintaining class distribution\n",
    "for image in unique_images:\n",
    "    image_df = usfws[usfws['filename'] == image]\n",
    "    classes = image_df['superclass'].unique()\n",
    "    \n",
    "    # Calculate the available class counts for the image\n",
    "    available_class_counts = {\n",
    "        cls: desired_class_counts[cls] - assigned_images['train'].get(cls, 0) - assigned_images['val'].get(cls, 0) - assigned_images['test'].get(cls, 0)\n",
    "        for cls in classes\n",
    "    }\n",
    "    \n",
    "    # Determine the set to assign the image based on available class counts\n",
    "    available_sets = ['train', 'val', 'test']\n",
    "    np.random.shuffle(available_sets)\n",
    "    \n",
    "    assigned = False\n",
    "    for set_name in available_sets:\n",
    "        set_df = usfws[usfws['filename'].isin(assigned_images[set_name])]\n",
    "        set_class_counts = set_df['superclass'].value_counts().to_dict()\n",
    "        \n",
    "        if all(available_class_counts[cls] <= set_class_counts.get(cls, 0) for cls in classes):\n",
    "            assigned_images[set_name][image] = True\n",
    "            assigned = True\n",
    "            break\n",
    "    \n",
    "    # If the image couldn't be assigned to any set, assign it to the set with the fewest images\n",
    "    if not assigned:\n",
    "        set_name = min(available_sets, key=lambda x: len(assigned_images[x]))\n",
    "        assigned_images[set_name][image] = True\n",
    "\n",
    "# Split the original dataframe based on the assigned sets\n",
    "train_df = usfws[usfws['filename'].isin(assigned_images['train'])]\n",
    "val_df = usfws[usfws['filename'].isin(assigned_images['val'])]\n",
    "test_df = usfws[usfws['filename'].isin(assigned_images['test'])]\n",
    "\n",
    "# Check the class distribution in each split\n",
    "print('Training set class distribution:')\n",
    "print(train_df['superclass'].value_counts(normalize=True))\n",
    "\n",
    "print('\\nValidation set class distribution:')\n",
    "print(val_df['superclass'].value_counts(normalize=True))\n",
    "\n",
    "print('\\nTest set class distribution:')\n",
    "print(test_df['superclass'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "Duck       0.534617\n",
      "Crane      0.379663\n",
      "Goose      0.084681\n",
      "Seagull    0.001039\n",
      "Name: category, dtype: float64\n",
      "\n",
      "Validation set class distribution:\n",
      "Duck       0.701394\n",
      "Seagull    0.189434\n",
      "Goose      0.106277\n",
      "Crane      0.002896\n",
      "Name: category, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "Duck       0.707356\n",
      "Seagull    0.166622\n",
      "Goose      0.124338\n",
      "Crane      0.001684\n",
      "Name: category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#SPLIT ZOONIVERSE\n",
    "\n",
    "# Define the desired class distribution in the train, validation, and test sets\n",
    "class_distribution = {'Crane': 0.18, 'Goose': 0.10, 'Duck': 0.62, 'Seagull': 0.10}\n",
    "\n",
    "# Calculate the total number of images in the dataset\n",
    "total_images = zoo['basefile'].nunique()\n",
    "\n",
    "# Calculate the desired number of images for each class in the train, validation, and test sets\n",
    "desired_class_counts = {cls: int(count * total_images) for cls, count in class_distribution.items()}\n",
    "\n",
    "# Create a dictionary to store the assigned images for each set and class\n",
    "assigned_images = defaultdict(dict)\n",
    "\n",
    "# Shuffle the unique images\n",
    "unique_images = zoo['basefile'].unique()\n",
    "np.random.shuffle(unique_images)\n",
    "\n",
    "# Assign images to sets while maintaining class distribution\n",
    "for image in unique_images:\n",
    "    image_df = zoo[zoo['basefile'] == image]\n",
    "    classes = image_df['category'].unique()\n",
    "    \n",
    "    # Calculate the available class counts for the image\n",
    "    available_class_counts = {\n",
    "        cls: desired_class_counts[cls] - assigned_images['train'].get(cls, 0) - assigned_images['val'].get(cls, 0) - assigned_images['test'].get(cls, 0)\n",
    "        for cls in classes\n",
    "    }\n",
    "    \n",
    "    # Determine the set to assign the image based on available class counts\n",
    "    available_sets = ['train', 'val', 'test']\n",
    "    np.random.shuffle(available_sets)\n",
    "    \n",
    "    assigned = False\n",
    "    for set_name in available_sets:\n",
    "        set_df = zoo[zoo['basefile'].isin(assigned_images[set_name])]\n",
    "        set_class_counts = set_df['category'].value_counts().to_dict()\n",
    "        \n",
    "        if all(available_class_counts[cls] <= set_class_counts.get(cls, 0) for cls in classes):\n",
    "            assigned_images[set_name][image] = True\n",
    "            assigned = True\n",
    "            break\n",
    "    \n",
    "    # If the image couldn't be assigned to any set, assign it to the set with the fewest images\n",
    "    if not assigned:\n",
    "        set_name = min(available_sets, key=lambda x: len(assigned_images[x]))\n",
    "        assigned_images[set_name][image] = True\n",
    "\n",
    "# Split the original dataframe based on the assigned sets\n",
    "train_df = zoo[zoo['basefile'].isin(assigned_images['train'])]\n",
    "val_df = zoo[zoo['basefile'].isin(assigned_images['val'])]\n",
    "test_df = zoo[zoo['basefile'].isin(assigned_images['test'])]\n",
    "\n",
    "# Check the class distribution in each split\n",
    "print('Training set class distribution:')\n",
    "print(train_df['category'].value_counts(normalize=True))\n",
    "\n",
    "print('\\nValidation set class distribution:')\n",
    "print(val_df['category'].value_counts(normalize=True))\n",
    "\n",
    "print('\\nTest set class distribution:')\n",
    "print(test_df['category'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "trainlist = set(train_df[\"basefile\"].unique())\n",
    "vallist = set(val_df[\"basefile\"].unique())\n",
    "testlist = set(test_df[\"basefile\"].unique())\n",
    "\n",
    "print(bool(set(testlist) & set(trainlist)))\n",
    "print(bool(set(testlist) & set(vallist)))\n",
    "print(bool(set(vallist) & set(trainlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the splits to separate CSV files if desired\n",
    "save = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/train_val_test/usfws_splits/\" \n",
    "train_df.to_csv(save+'train.csv', index=False)\n",
    "val_df.to_csv(save+'val.csv', index=False)\n",
    "test_df.to_csv(save+'test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
